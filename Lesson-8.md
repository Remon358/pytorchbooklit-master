#### Lesson-8 

### 深度学习概述

深度学习,实际上来说就是一种模仿人脑的学习,它是起源于人工神经网络的研究.它含多隐层的[多层感知器](https://baike.baidu.com/item/多层感知器)就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。

深度学习(DL, Deep Learning)是[机器学习](https://baike.baidu.com/item/机器学习/217599)(ML, Machine Learning)领域中一个新的研究方向，它被引入机器学习使其更接近于最初的目标——[人工智能](https://baike.baidu.com/item/人工智能/9180)(AI, Artificial Intelligence)。 [1] 

深度学习是学习[样本数据](https://baike.baidu.com/item/样本数据/12726279)的内在规律和表示层次，这些学习过程中获得的信息对诸如文字，[图像](https://baike.baidu.com/item/图像/773234)和声音等数据的解释有很大的帮助。它的最终目标是让机器能够像人一样具有分析学习能力，能够识别文字、图像和声音等数据。 深度学习是一个复杂的机器学习算法，在语音和图像识别方面取得的效果，远远超过先前相关技术。 [1] 

深度学习在[搜索技术](https://baike.baidu.com/item/搜索技术/1447197)，[数据挖掘](https://baike.baidu.com/item/数据挖掘/216477)，机器学习，[机器翻译](https://baike.baidu.com/item/机器翻译/411793)，[自然语言处理](https://baike.baidu.com/item/自然语言处理/365730)，[多媒体学习](https://baike.baidu.com/item/多媒体学习/10528812)，语音，推荐和个性化技术，以及其他相关领域都取得了很多成果。深度学习使机器模仿视听和思考等人类的活动，解决了很多复杂的模式识别难题，使得人工智能相关技术取得了很大进步。

1. ##### 推动机器学习发展的三大因素: 硬件, 数据, 算法

   1.1 高速, 大规模集成电路的发展. GPU并行运算的发展

   1.2 大量的数据产生, 每天都会产生海量的数据资源. 

   1.3 丰富的软件支持包.

2. ##### 机器学习, 深度学习和人工智能

   人工智能是[计算机](https://baike.baidu.com/item/计算机)科学的一个分支，它企图了解智能的实质，并生产出一种新的能以[人类智能](https://baike.baidu.com/item/人类智能/2287229)相似的方式做出反应的智能机器，该领域的研究包括机器人、语言识别、图像识别、自然语言处理和[专家系统](https://baike.baidu.com/item/专家系统/267819)等。人工智能从诞生以来，理论和技术日益成熟，应用领域也不断扩大，可以设想，未来人工智能带来的科技产品，将会是人类[智慧](https://baike.baidu.com/item/智慧/129438)的“容器”。人工智能可以对人的意识、思维的信息过程的模拟。人工智能不是人的智能，但能像人那样思考、也可能超过人的智能。

   深度学习源于人工神经网络的研究，它被引入机器学习使其更接近于最初的目标——[人工智能](https://baike.baidu.com/item/人工智能/9180)(AI, Artificial Intelligence)。

   机器学习是一门多领域交叉学科，涉及概率论、统计学、[逼近论](https://baike.baidu.com/item/逼近论/967006)、[凸分析](https://baike.baidu.com/item/凸分析)、[算法复杂度](https://baike.baidu.com/item/算法复杂度)理论等多门学科。专门研究计算机怎样模拟或实现人类的[学习行为](https://baike.baidu.com/item/学习行为/5482132)，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。

3. ##### 深度学习的框架

   深度学习在研究初期, 科研人员需要编写大量重复性代码. 一方面,  大量代码的编写增加了入门的门槛, 同时增加了代码出错的风险, 科研人员需要花费大量的精力用于代码的维护工作. 另一方面, 由于编程规范不统一, 以及编程语言的多样性, 使得学术交流较为困难, 严重阻止的深度学习的发展. 因此, 为了避免重复"造轮子"的尴尬局面,同时提高工作效率. 一些研究人员开始着力开发编写深度学习框架.
   
   深度学习的发展,以及广泛使用, 得益于深度学习框架的易用性.
   
   目前业界使用比较普遍的深度学习框架有:
   
   1. TensorFlow: TensorFlow 是一个开源的、基于 Python 的机器学习框架，它由 Google 开发，并在图形分类、音频处理、推荐系统和自然语言处理等场景下有着丰富的应用，是目前最热门的机器学习框架。TensorFlow™ 是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。节点（Nodes）在图中表示数学操作，图中的线（edges）则表示在节点间相互联系的多维数据数组，即张量（tensor）。它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。TensorFlow 最初由Google大脑小组（隶属于Google机器智能研究机构）的研究员和工程师们开发出来，用于机器学习和深度神经网络方面的研究，但这个系统的通用性使其也可广泛用于其他计算领域。
       Tensorflow是谷歌公司在**2015年9月**开源的一个深度学习框架
   
   2. Pytorch: 2017年1月，由[Facebook](https://baike.baidu.com/item/Facebook/7449587)[人工智能](https://baike.baidu.com/item/人工智能/9180)研究院（FAIR）基于Torch推出了PyTorch。它是一个基于Python的可续计算包，提供两个高级功能：1、具有强大的GPU加速的张量计算（如NumPy）。2、包含自动求导系统的深度神经网络。其优点是 入门简单, 框架简介高效, 一直在维护和开发
   
   3. Keras: Keras是一个高层神经网络API，Keras由纯Python编写而成并基[Tensorflow](https://github.com/tensorflow/tensorflow)、[Theano](https://github.com/Theano/Theano)以及[CNTK](https://github.com/Microsoft/cntk)后端。Keras 为支持快速实验而生，能够把你的idea迅速转换为结果。
   
   4. Caffe: Convolutional Architecture for fast feature embedding,  由加州大学伯克利分校的贾扬清开发,使用C++编写, 是一个清晰且高效的开源深度学习框架, 目前由伯克利视觉学习中心进行维护. 只提供C++接口, 并没有提供Python接口. 
   
      Caffe的流行,源于ImageNet比赛中, 使用的网络都是caffe写的, 想要参加比赛就必须掌握Caffe的网络模型接口, 目前caffe2的已经开源 .
   
   5. 百度飞桨:飞桨（PaddlePaddle）以百度多年的深度学习技术研究和业务应用为基础，集深度学习核心训练和推理框架、基础模型库、端到端开发套件、丰富的工具组件于一体。是中国首个自主研发、功能完备、开源开放的产业级深度学习平台. 其官方四大领先技术包括: 开发便捷的深度学习框架, 超大规模深度学习模型训练技术;  多端多平台部署的高性能推理引擎, 以及产业级的开源模型库. 具有丰富的硬件支持, 以及多家国内落地应用产业.
   
   
